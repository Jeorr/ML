{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlh0H0Upnu05gMR+s05l06",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeorr/ML/blob/main/Lab1Tensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqznl8qfYyYc",
        "outputId": "30974179-2252-4171-fc1e-cf70b591aa8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 307002624.0000 - mae: 13100.7090 - val_loss: 310030784.0000 - val_mae: 12644.3174\n",
            "Epoch 2/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 342443936.0000 - mae: 13874.3125 - val_loss: 307340640.0000 - val_mae: 12558.2041\n",
            "Epoch 3/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 345768096.0000 - mae: 13784.9902 - val_loss: 294496800.0000 - val_mae: 12165.8535\n",
            "Epoch 4/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 285153504.0000 - mae: 12453.6719 - val_loss: 255171024.0000 - val_mae: 10951.7441\n",
            "Epoch 5/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 249064256.0000 - mae: 11020.9473 - val_loss: 174786912.0000 - val_mae: 8382.7510\n",
            "Epoch 6/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 126211264.0000 - mae: 7317.0718 - val_loss: 84266456.0000 - val_mae: 5430.1387\n",
            "Epoch 7/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 76490488.0000 - mae: 5608.5591 - val_loss: 46539552.0000 - val_mae: 4836.3682\n",
            "Epoch 8/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45897268.0000 - mae: 5029.9644 - val_loss: 39477844.0000 - val_mae: 4660.3042\n",
            "Epoch 9/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 44878156.0000 - mae: 4967.8730 - val_loss: 36134332.0000 - val_mae: 4286.5537\n",
            "Epoch 10/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 42988716.0000 - mae: 4736.3052 - val_loss: 34089360.0000 - val_mae: 4113.9194\n",
            "Epoch 11/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33396982.0000 - mae: 4116.6367 - val_loss: 33288622.0000 - val_mae: 3914.5330\n",
            "Epoch 12/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34209172.0000 - mae: 3932.9304 - val_loss: 32234518.0000 - val_mae: 3879.2869\n",
            "Epoch 13/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 37353368.0000 - mae: 4137.1094 - val_loss: 31780434.0000 - val_mae: 3770.8069\n",
            "Epoch 14/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34117784.0000 - mae: 4006.2144 - val_loss: 31346376.0000 - val_mae: 3743.9116\n",
            "Epoch 15/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 36777680.0000 - mae: 4136.8901 - val_loss: 31007246.0000 - val_mae: 3671.0264\n",
            "Epoch 16/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34330104.0000 - mae: 3826.6638 - val_loss: 31066246.0000 - val_mae: 3622.4290\n",
            "Epoch 17/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 36046096.0000 - mae: 3909.2153 - val_loss: 30880594.0000 - val_mae: 3591.8586\n",
            "Epoch 18/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29556574.0000 - mae: 3597.7776 - val_loss: 30201790.0000 - val_mae: 3582.5471\n",
            "Epoch 19/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26991662.0000 - mae: 3483.2546 - val_loss: 30089556.0000 - val_mae: 3546.6194\n",
            "Epoch 20/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 35632916.0000 - mae: 3866.8508 - val_loss: 29905208.0000 - val_mae: 3550.4937\n",
            "Epoch 21/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31106852.0000 - mae: 3570.6318 - val_loss: 29753420.0000 - val_mae: 3512.6536\n",
            "Epoch 22/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28983978.0000 - mae: 3547.8020 - val_loss: 29537570.0000 - val_mae: 3490.0828\n",
            "Epoch 23/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 37209732.0000 - mae: 3966.6780 - val_loss: 29468948.0000 - val_mae: 3487.9551\n",
            "Epoch 24/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27279102.0000 - mae: 3495.0703 - val_loss: 28934142.0000 - val_mae: 3460.7148\n",
            "Epoch 25/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29314928.0000 - mae: 3475.0913 - val_loss: 28930784.0000 - val_mae: 3452.4224\n",
            "Epoch 26/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31338144.0000 - mae: 3656.1372 - val_loss: 28603684.0000 - val_mae: 3481.9177\n",
            "Epoch 27/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30874714.0000 - mae: 3597.6504 - val_loss: 28558480.0000 - val_mae: 3401.6233\n",
            "Epoch 28/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29977754.0000 - mae: 3539.2412 - val_loss: 28262734.0000 - val_mae: 3423.3342\n",
            "Epoch 29/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34263192.0000 - mae: 3755.3416 - val_loss: 28171768.0000 - val_mae: 3402.7996\n",
            "Epoch 30/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27312804.0000 - mae: 3388.1165 - val_loss: 27759864.0000 - val_mae: 3375.4495\n",
            "Epoch 31/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33609220.0000 - mae: 3765.6345 - val_loss: 27750608.0000 - val_mae: 3354.4106\n",
            "Epoch 32/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30822366.0000 - mae: 3594.5349 - val_loss: 27507100.0000 - val_mae: 3335.8352\n",
            "Epoch 33/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31976440.0000 - mae: 3699.0435 - val_loss: 27333768.0000 - val_mae: 3348.0808\n",
            "Epoch 34/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 32823468.0000 - mae: 3785.9817 - val_loss: 27314800.0000 - val_mae: 3306.9719\n",
            "Epoch 35/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25372608.0000 - mae: 3267.2373 - val_loss: 27076752.0000 - val_mae: 3291.6694\n",
            "Epoch 36/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27222320.0000 - mae: 3220.7915 - val_loss: 26983006.0000 - val_mae: 3307.5852\n",
            "Epoch 37/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28025262.0000 - mae: 3428.8672 - val_loss: 26766322.0000 - val_mae: 3332.1821\n",
            "Epoch 38/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28104786.0000 - mae: 3402.4036 - val_loss: 26847330.0000 - val_mae: 3287.6841\n",
            "Epoch 39/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26579806.0000 - mae: 3444.1206 - val_loss: 26408860.0000 - val_mae: 3253.9243\n",
            "Epoch 40/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27455668.0000 - mae: 3411.2087 - val_loss: 26285760.0000 - val_mae: 3227.2170\n",
            "Epoch 41/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 25825218.0000 - mae: 3234.6514 - val_loss: 26271978.0000 - val_mae: 3254.0286\n",
            "Epoch 42/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27645960.0000 - mae: 3296.4336 - val_loss: 26195508.0000 - val_mae: 3251.7168\n",
            "Epoch 43/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30504678.0000 - mae: 3548.7297 - val_loss: 26034388.0000 - val_mae: 3286.5017\n",
            "Epoch 44/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 26819582.0000 - mae: 3391.8257 - val_loss: 26025302.0000 - val_mae: 3200.1399\n",
            "Epoch 45/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29475958.0000 - mae: 3466.8633 - val_loss: 25644276.0000 - val_mae: 3263.1895\n",
            "Epoch 46/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27882116.0000 - mae: 3320.0745 - val_loss: 25728198.0000 - val_mae: 3190.1846\n",
            "Epoch 47/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30259550.0000 - mae: 3449.6482 - val_loss: 25662980.0000 - val_mae: 3194.4795\n",
            "Epoch 48/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31710248.0000 - mae: 3504.6650 - val_loss: 25651812.0000 - val_mae: 3172.6938\n",
            "Epoch 49/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29047778.0000 - mae: 3337.9329 - val_loss: 25428104.0000 - val_mae: 3200.4675\n",
            "Epoch 50/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26830128.0000 - mae: 3314.4998 - val_loss: 25375606.0000 - val_mae: 3201.8079\n",
            "Epoch 51/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26908454.0000 - mae: 3334.7012 - val_loss: 25318620.0000 - val_mae: 3161.5581\n",
            "Epoch 52/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30664188.0000 - mae: 3475.9558 - val_loss: 25472928.0000 - val_mae: 3111.6355\n",
            "Epoch 53/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26831990.0000 - mae: 3260.0227 - val_loss: 25072514.0000 - val_mae: 3161.9199\n",
            "Epoch 54/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29905462.0000 - mae: 3404.7649 - val_loss: 24887750.0000 - val_mae: 3158.0955\n",
            "Epoch 55/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28970162.0000 - mae: 3449.0142 - val_loss: 24994686.0000 - val_mae: 3110.1626\n",
            "Epoch 56/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25065708.0000 - mae: 3211.8528 - val_loss: 24799850.0000 - val_mae: 3161.3398\n",
            "Epoch 57/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32673376.0000 - mae: 3640.0291 - val_loss: 24670734.0000 - val_mae: 3099.7219\n",
            "Epoch 58/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29698614.0000 - mae: 3381.5723 - val_loss: 24572188.0000 - val_mae: 3128.7051\n",
            "Epoch 59/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25135848.0000 - mae: 3193.9639 - val_loss: 24635030.0000 - val_mae: 3155.7888\n",
            "Epoch 60/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33578904.0000 - mae: 3675.1831 - val_loss: 24881900.0000 - val_mae: 3047.4270\n",
            "Epoch 61/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30233220.0000 - mae: 3430.9749 - val_loss: 24445128.0000 - val_mae: 3113.6616\n",
            "Epoch 62/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27470444.0000 - mae: 3375.1104 - val_loss: 24353410.0000 - val_mae: 3114.5073\n",
            "Epoch 63/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26197032.0000 - mae: 3229.1123 - val_loss: 24330060.0000 - val_mae: 3096.1816\n",
            "Epoch 64/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29881666.0000 - mae: 3447.9380 - val_loss: 24520432.0000 - val_mae: 3065.0847\n",
            "Epoch 65/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26907814.0000 - mae: 3130.7090 - val_loss: 24406978.0000 - val_mae: 3068.9375\n",
            "Epoch 66/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29641588.0000 - mae: 3389.6318 - val_loss: 24179552.0000 - val_mae: 3116.3716\n",
            "Epoch 67/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27082728.0000 - mae: 3276.5398 - val_loss: 24135914.0000 - val_mae: 3076.8496\n",
            "Epoch 68/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24966988.0000 - mae: 3176.1191 - val_loss: 23795326.0000 - val_mae: 3100.4485\n",
            "Epoch 69/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26584998.0000 - mae: 3214.9177 - val_loss: 24225560.0000 - val_mae: 2981.3367\n",
            "Epoch 70/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27289514.0000 - mae: 3200.7959 - val_loss: 23822386.0000 - val_mae: 3067.8525\n",
            "Epoch 71/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26742098.0000 - mae: 3166.4932 - val_loss: 23798772.0000 - val_mae: 3116.0466\n",
            "Epoch 72/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29308670.0000 - mae: 3550.1658 - val_loss: 23984716.0000 - val_mae: 2914.9333\n",
            "Epoch 73/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29638310.0000 - mae: 3324.2236 - val_loss: 24007450.0000 - val_mae: 2995.3826\n",
            "Epoch 74/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25543972.0000 - mae: 3238.7839 - val_loss: 23626802.0000 - val_mae: 3131.7444\n",
            "Epoch 75/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28143574.0000 - mae: 3451.1345 - val_loss: 23879322.0000 - val_mae: 3004.9336\n",
            "Epoch 76/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29930664.0000 - mae: 3356.8269 - val_loss: 23651404.0000 - val_mae: 3058.7004\n",
            "Epoch 77/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27131720.0000 - mae: 3378.9065 - val_loss: 23641222.0000 - val_mae: 2938.1514\n",
            "Epoch 78/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24280240.0000 - mae: 2916.3120 - val_loss: 23567698.0000 - val_mae: 2995.2117\n",
            "Epoch 79/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25743396.0000 - mae: 3122.6118 - val_loss: 23527880.0000 - val_mae: 2999.6367\n",
            "Epoch 80/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27707950.0000 - mae: 3245.5938 - val_loss: 23212272.0000 - val_mae: 3044.1350\n",
            "Epoch 81/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30452446.0000 - mae: 3457.9016 - val_loss: 23797342.0000 - val_mae: 2943.8003\n",
            "Epoch 82/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27288722.0000 - mae: 3167.8042 - val_loss: 23386578.0000 - val_mae: 3060.8828\n",
            "Epoch 83/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25595994.0000 - mae: 3299.7446 - val_loss: 23265010.0000 - val_mae: 2953.1929\n",
            "Epoch 84/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27280762.0000 - mae: 3239.8792 - val_loss: 23333632.0000 - val_mae: 2951.5764\n",
            "Epoch 85/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22652526.0000 - mae: 2898.9075 - val_loss: 22999812.0000 - val_mae: 3030.0757\n",
            "Epoch 86/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22450326.0000 - mae: 3000.6804 - val_loss: 22982998.0000 - val_mae: 3030.2588\n",
            "Epoch 87/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25529614.0000 - mae: 3224.4900 - val_loss: 22899874.0000 - val_mae: 3001.3894\n",
            "Epoch 88/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25603950.0000 - mae: 3236.3560 - val_loss: 22908760.0000 - val_mae: 2973.5132\n",
            "Epoch 89/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 23703170.0000 - mae: 3045.2910 - val_loss: 22969414.0000 - val_mae: 2958.1892\n",
            "Epoch 90/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30507650.0000 - mae: 3373.7849 - val_loss: 22978512.0000 - val_mae: 2956.5071\n",
            "Epoch 91/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25200478.0000 - mae: 3114.1731 - val_loss: 22787466.0000 - val_mae: 2962.9246\n",
            "Epoch 92/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23428688.0000 - mae: 2937.2349 - val_loss: 23025086.0000 - val_mae: 2946.2476\n",
            "Epoch 93/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28504688.0000 - mae: 3196.5911 - val_loss: 22688828.0000 - val_mae: 2936.4148\n",
            "Epoch 94/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28429284.0000 - mae: 3161.1709 - val_loss: 22624978.0000 - val_mae: 2963.3643\n",
            "Epoch 95/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29543308.0000 - mae: 3367.8069 - val_loss: 22883974.0000 - val_mae: 2939.1836\n",
            "Epoch 96/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24329962.0000 - mae: 3043.4285 - val_loss: 22512760.0000 - val_mae: 2949.6890\n",
            "Epoch 97/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25646570.0000 - mae: 3190.2407 - val_loss: 22902566.0000 - val_mae: 2887.2991\n",
            "Epoch 98/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22764656.0000 - mae: 2947.8425 - val_loss: 22568910.0000 - val_mae: 2880.1104\n",
            "Epoch 99/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28353990.0000 - mae: 3296.9561 - val_loss: 22412750.0000 - val_mae: 2925.8962\n",
            "Epoch 100/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24860000.0000 - mae: 3056.9041 - val_loss: 22452028.0000 - val_mae: 2909.6609\n",
            "Epoch 101/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28494272.0000 - mae: 3286.1958 - val_loss: 22365010.0000 - val_mae: 2948.0771\n",
            "Epoch 102/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24812986.0000 - mae: 3034.5149 - val_loss: 22175548.0000 - val_mae: 2956.3904\n",
            "Epoch 103/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 25776676.0000 - mae: 3221.7959 - val_loss: 22268258.0000 - val_mae: 2836.2405\n",
            "Epoch 104/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27554804.0000 - mae: 3093.6633 - val_loss: 22474486.0000 - val_mae: 2833.9021\n",
            "Epoch 105/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27557930.0000 - mae: 3221.3513 - val_loss: 21980224.0000 - val_mae: 2914.8555\n",
            "Epoch 106/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24007120.0000 - mae: 3028.3936 - val_loss: 22065320.0000 - val_mae: 2883.6162\n",
            "Epoch 107/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25015814.0000 - mae: 3054.1665 - val_loss: 22142810.0000 - val_mae: 2914.0432\n",
            "Epoch 108/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23757290.0000 - mae: 3048.9102 - val_loss: 22391564.0000 - val_mae: 2881.6509\n",
            "Epoch 109/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25875676.0000 - mae: 3032.6624 - val_loss: 22054962.0000 - val_mae: 2871.8389\n",
            "Epoch 110/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 22319120.0000 - mae: 2900.6562 - val_loss: 21929516.0000 - val_mae: 2856.6865\n",
            "Epoch 111/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24151366.0000 - mae: 3013.4575 - val_loss: 22146000.0000 - val_mae: 2855.7595\n",
            "Epoch 112/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25072440.0000 - mae: 3050.2361 - val_loss: 22121204.0000 - val_mae: 2850.3259\n",
            "Epoch 113/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24460156.0000 - mae: 3158.2144 - val_loss: 21917038.0000 - val_mae: 2919.5493\n",
            "Epoch 114/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27504130.0000 - mae: 3278.1360 - val_loss: 21669852.0000 - val_mae: 2816.1294\n",
            "Epoch 115/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26858152.0000 - mae: 3287.0825 - val_loss: 21798908.0000 - val_mae: 2781.6953\n",
            "Epoch 116/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 24407530.0000 - mae: 3009.6245 - val_loss: 21832422.0000 - val_mae: 2788.8164\n",
            "Epoch 117/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21715908.0000 - mae: 2822.1543 - val_loss: 21610108.0000 - val_mae: 2997.2026\n",
            "Epoch 118/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 23052200.0000 - mae: 3065.9678 - val_loss: 21684844.0000 - val_mae: 2820.4241\n",
            "Epoch 119/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 22995378.0000 - mae: 2996.8157 - val_loss: 21966762.0000 - val_mae: 2741.2266\n",
            "Epoch 120/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 20690288.0000 - mae: 2780.3362 - val_loss: 21485106.0000 - val_mae: 2768.5068\n",
            "Epoch 121/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 25627936.0000 - mae: 3164.6697 - val_loss: 22030006.0000 - val_mae: 2747.7976\n",
            "Epoch 122/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 24491754.0000 - mae: 3026.8098 - val_loss: 21369674.0000 - val_mae: 2809.8586\n",
            "Epoch 123/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 23598894.0000 - mae: 3003.7334 - val_loss: 21511920.0000 - val_mae: 2758.9756\n",
            "Epoch 124/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 24486770.0000 - mae: 2989.3279 - val_loss: 21532718.0000 - val_mae: 2853.7542\n",
            "Epoch 125/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26450080.0000 - mae: 3120.2285 - val_loss: 21640470.0000 - val_mae: 2865.6829\n",
            "Epoch 126/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26145752.0000 - mae: 2951.9763 - val_loss: 21343120.0000 - val_mae: 2796.1365\n",
            "Epoch 127/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 24199278.0000 - mae: 3048.0891 - val_loss: 21388740.0000 - val_mae: 2795.0637\n",
            "Epoch 128/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22701154.0000 - mae: 3033.8662 - val_loss: 21581470.0000 - val_mae: 2772.2363\n",
            "Epoch 129/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24281956.0000 - mae: 2942.6240 - val_loss: 21340708.0000 - val_mae: 2809.0371\n",
            "Epoch 130/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26380124.0000 - mae: 3199.7302 - val_loss: 21340676.0000 - val_mae: 2782.9824\n",
            "Epoch 131/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 24352766.0000 - mae: 3062.7202 - val_loss: 21245926.0000 - val_mae: 2808.1331\n",
            "Epoch 132/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27830526.0000 - mae: 3251.3000 - val_loss: 21656662.0000 - val_mae: 2734.2302\n",
            "Epoch 133/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27527616.0000 - mae: 3096.9973 - val_loss: 21604342.0000 - val_mae: 2751.0591\n",
            "Epoch 134/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18985050.0000 - mae: 2653.0920 - val_loss: 21254988.0000 - val_mae: 2759.0605\n",
            "Epoch 135/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21324586.0000 - mae: 2852.8086 - val_loss: 21282118.0000 - val_mae: 2773.0393\n",
            "Epoch 136/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23742466.0000 - mae: 2898.0920 - val_loss: 21488482.0000 - val_mae: 2782.3206\n",
            "Epoch 137/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26213884.0000 - mae: 3299.8633 - val_loss: 21483658.0000 - val_mae: 2776.5283\n",
            "Epoch 138/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21412112.0000 - mae: 2763.1096 - val_loss: 21177454.0000 - val_mae: 2730.5896\n",
            "Epoch 139/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21286320.0000 - mae: 2860.2603 - val_loss: 21272556.0000 - val_mae: 2726.5417\n",
            "Epoch 140/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23850206.0000 - mae: 3015.8459 - val_loss: 21127030.0000 - val_mae: 2778.6401\n",
            "Epoch 141/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25731836.0000 - mae: 3080.4153 - val_loss: 21343650.0000 - val_mae: 2677.9260\n",
            "Epoch 142/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25221096.0000 - mae: 3000.0149 - val_loss: 21423416.0000 - val_mae: 2766.2227\n",
            "Epoch 143/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23102066.0000 - mae: 2860.4937 - val_loss: 21198630.0000 - val_mae: 2676.0876\n",
            "Epoch 144/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 24975090.0000 - mae: 2972.5776 - val_loss: 21383354.0000 - val_mae: 2726.4265\n",
            "Epoch 145/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23600798.0000 - mae: 2926.2961 - val_loss: 21226654.0000 - val_mae: 2691.1042\n",
            "Epoch 146/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20881796.0000 - mae: 2783.6995 - val_loss: 21050632.0000 - val_mae: 2815.7114\n",
            "Epoch 147/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24619474.0000 - mae: 3071.6833 - val_loss: 21129952.0000 - val_mae: 2714.1099\n",
            "Epoch 148/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24932792.0000 - mae: 3098.8547 - val_loss: 21124744.0000 - val_mae: 2737.1909\n",
            "Epoch 149/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 22923130.0000 - mae: 3034.0869 - val_loss: 21285950.0000 - val_mae: 2622.8184\n",
            "Epoch 150/150\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 24490620.0000 - mae: 2905.9937 - val_loss: 21115518.0000 - val_mae: 2783.0908\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Mean Absolute Error (MAE): 2687.3198987981573\n",
            "Mean Squared Error (MSE): 19880396.52780313\n",
            "MAE = 2687.3198987981573 є занадто великим.\n",
            "MSE = 19880396.52780313 є прийнятним в порівнянні з квадратом середнього.\n"
          ]
        }
      ],
      "source": [
        "# Встановлення бібліотек\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Завантаження даних\n",
        "url = \"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/refs/heads/master/insurance.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Перетворення номінативних даних на числові за допомогою LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "data['sex'] = label_encoder.fit_transform(data['sex'])\n",
        "data['smoker'] = label_encoder.fit_transform(data['smoker'])\n",
        "data['region'] = label_encoder.fit_transform(data['region'])\n",
        "\n",
        "# Визначення вхідних та цільових змінних\n",
        "X = data.drop(['charges'], axis=1)  # Всі змінні, крім 'charges', є вхідними\n",
        "y = data['charges']  # 'charges' — цільова змінна\n",
        "\n",
        "# Розділення на тренувальні та тестові набори (80% на тренування, 20% на тестування)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Нормалізація даних\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Створення моделі нейронної мережі\n",
        "model = Sequential()\n",
        "\n",
        "# Додавання шарів\n",
        "model.add(Dense(256, input_shape=(X_train.shape[1],), activation='relu'))  # Вхідний та перший прихований шар\n",
        "model.add(Dropout(0.2))  # Додаємо Dropout для уникнення перенавчання\n",
        "model.add(Dense(128, activation='relu'))  # Другий прихований шар\n",
        "model.add(Dropout(0.2))  # Додаємо Dropout\n",
        "model.add(Dense(64, activation='relu'))  # Третій прихований шар\n",
        "model.add(Dense(1))  # Вихідний шар (одне значення, оскільки ми прогнозуємо числове значення)\n",
        "\n",
        "# Компіляція моделі\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Навчання моделі\n",
        "history = model.fit(X_train, y_train, validation_split=0.2, epochs=150, batch_size=32, verbose=1)\n",
        "\n",
        "# Прогнозування на тестовій вибірці\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Обчислення метрик MAE та MSE\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# Виведення результатів\n",
        "print(f'Mean Absolute Error (MAE): {mae}')\n",
        "print(f'Mean Squared Error (MSE): {mse}')\n",
        "\n",
        "# Перевірка, чи MAE є прийнятним\n",
        "acceptable_mae = np.mean(y) * 0.1  # 10% від середньої вартості\n",
        "\n",
        "if mae <= acceptable_mae:\n",
        "    print(f\"MAE = {mae} є прийнятним.\")\n",
        "else:\n",
        "    print(f\"MAE = {mae} є занадто великим.\")\n",
        "\n",
        "# Додатково, ви можете порівняти MSE з квадратом середнього\n",
        "mse_comparison = np.mean(y) ** 2\n",
        "\n",
        "if mse <= mse_comparison:\n",
        "    print(f\"MSE = {mse} є прийнятним в порівнянні з квадратом середнього.\")\n",
        "else:\n",
        "    print(f\"MSE = {mse} є занадто великим.\")\n"
      ]
    }
  ]
}