{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1P-ZW-fsXddhQ7sKmIvU-zqI_I2RIYyhA",
      "authorship_tag": "ABX9TyPE7SqfxAv5/FiNxli97CZa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeorr/ML/blob/main/Lab2PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OJIsBdtSoJQ",
        "outputId": "ffd127f7-0685-4498-e28b-377dd166bc42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файли успішно розархівовано в /content/Lab2\n",
            "Використовується пристрій: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 22.3780, Train Accuracy: 0.8435\n",
            "Validation Accuracy: 0.9030\n",
            "Epoch [2/10], Loss: 14.5955, Train Accuracy: 0.9030\n",
            "Validation Accuracy: 0.9130\n",
            "Epoch [3/10], Loss: 13.5741, Train Accuracy: 0.9160\n",
            "Validation Accuracy: 0.9210\n",
            "Epoch [4/10], Loss: 10.7171, Train Accuracy: 0.9315\n",
            "Validation Accuracy: 0.9150\n",
            "Epoch [5/10], Loss: 11.6699, Train Accuracy: 0.9250\n",
            "Validation Accuracy: 0.9040\n",
            "Epoch [6/10], Loss: 9.5191, Train Accuracy: 0.9430\n",
            "Validation Accuracy: 0.9210\n",
            "Epoch [7/10], Loss: 9.5259, Train Accuracy: 0.9395\n",
            "Validation Accuracy: 0.9230\n",
            "Epoch [8/10], Loss: 8.5353, Train Accuracy: 0.9385\n",
            "Validation Accuracy: 0.9240\n",
            "Epoch [9/10], Loss: 8.0570, Train Accuracy: 0.9515\n",
            "Validation Accuracy: 0.9140\n",
            "Epoch [10/10], Loss: 7.8776, Train Accuracy: 0.9520\n",
            "Validation Accuracy: 0.9150\n",
            "Mean Absolute Error (MAE): 0.08500000089406967\n",
            "Mean Squared Error (MSE): 0.08500000089406967\n",
            "   FileName PredictedClass\n",
            "0     4.jpg            Dog\n",
            "1     2.jpg            Dog\n",
            "2     1.jpg            Dog\n",
            "3    14.jpg            Dog\n",
            "4    22.jpg            Cat\n",
            "5    49.jpg            Dog\n",
            "6    24.jpg            Dog\n",
            "7    16.jpg            Cat\n",
            "8    18.jpg            Dog\n",
            "9    20.jpg            Cat\n",
            "10   23.jpg            Dog\n",
            "11   37.jpg            Cat\n",
            "12   32.jpg            Cat\n",
            "13   45.jpg            Cat\n",
            "14   29.jpg            Dog\n",
            "15   41.jpg            Dog\n",
            "16   15.jpg            Cat\n",
            "17   44.jpg            Dog\n",
            "18   21.jpg            Dog\n",
            "19   42.jpg            Dog\n",
            "20   34.jpg            Cat\n",
            "21    8.jpg            Cat\n",
            "22    3.jpg            Dog\n",
            "23   33.jpg            Dog\n",
            "24   25.jpg            Dog\n",
            "25    6.jpg            Cat\n",
            "26   11.jpg            Cat\n",
            "27   27.jpg            Dog\n",
            "28   39.jpg            Dog\n",
            "29   26.jpg            Dog\n",
            "30   10.jpg            Dog\n",
            "31   50.jpg            Cat\n",
            "32   35.jpg            Cat\n",
            "33   28.jpg            Cat\n",
            "34   48.jpg            Dog\n",
            "35   38.jpg            Cat\n",
            "36   46.jpg            Dog\n",
            "37   13.jpg            Cat\n",
            "38    5.jpg            Cat\n",
            "39   36.jpg            Cat\n",
            "40   30.jpg            Dog\n",
            "41   47.jpg            Cat\n",
            "42   19.jpg            Cat\n",
            "43   40.jpg            Cat\n",
            "44    7.jpg            Cat\n",
            "45   31.jpg            Dog\n",
            "46   17.jpg            Dog\n",
            "47    9.jpg            Cat\n",
            "48   12.jpg            Dog\n",
            "49   43.jpg            Dog\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.io import read_image\n",
        "from torchvision.transforms import Compose, Resize, Normalize\n",
        "from pathlib import Path\n",
        "from torchvision.transforms import ToPILImage\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Розархівування zip файлу, якщо він існує\n",
        "zip_path = '/content/drive/MyDrive/ML/cats_and_dogs.zip'\n",
        "extract_to_path = '/content/Lab2'\n",
        "if os.path.exists(zip_path):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to_path)\n",
        "    print(f\"Файли успішно розархівовано в {extract_to_path}\")\n",
        "else:\n",
        "    print(f\"Файл {zip_path} не знайдено.\")\n",
        "\n",
        "# Підготовка пристрою\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Використовується пристрій: {device}\")\n",
        "\n",
        "# Параметри\n",
        "batch_size = 32\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "image_size = (150, 150)\n",
        "\n",
        "# Шляхи\n",
        "train_dir = '/content/Lab2/cats_and_dogs/train'\n",
        "validation_dir = '/content/Lab2/cats_and_dogs/validation'\n",
        "test_dir = '/content/Lab2/cats_and_dogs/test'\n",
        "\n",
        "# Пройдемося по всіх файлах у папці\n",
        "for img_path in Path(test_dir).iterdir():\n",
        "    if img_path.is_file() and img_path.suffix in [\".jpg\", \".png\", \".jpeg\"]:  # Фільтруємо лише зображення\n",
        "        # Завантажуємо зображення\n",
        "        img = read_image(str(img_path))\n",
        "        img = test_transform(to_pil(img)).unsqueeze(0).to(device)\n",
        "\n",
        "# Трансформації зображень\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Завантаження даних\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
        "validation_dataset = datasets.ImageFolder(validation_dir, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Завантаження попередньо натренованої моделі\n",
        "base_model = models.efficientnet_b0(pretrained=True)\n",
        "\n",
        "# Заморожуємо верхні шари\n",
        "for param in base_model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Налаштування голови моделі\n",
        "num_features = base_model.classifier[1].in_features\n",
        "base_model.classifier = nn.Sequential(\n",
        "    nn.Linear(num_features, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.4),\n",
        "    nn.Linear(128, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "base_model = base_model.to(device)\n",
        "\n",
        "# Функція втрат та оптимізатор\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(base_model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Тренування\n",
        "for epoch in range(num_epochs):\n",
        "    base_model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = base_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        preds = (outputs > 0.5).float()\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_accuracy = correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "    # Валідація\n",
        "    base_model.eval()\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in validation_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
        "            outputs = base_model(inputs)\n",
        "            preds = (outputs > 0.5).float()\n",
        "            correct_val += (preds == labels).sum().item()\n",
        "            total_val += labels.size(0)\n",
        "    val_accuracy = correct_val / total_val\n",
        "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "# Передбачення на валідаційному наборі\n",
        "base_model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in validation_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
        "        outputs = base_model(inputs)\n",
        "        preds = (outputs > 0.5).float()\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Обчислення метрик\n",
        "mae = mean_absolute_error(all_labels, all_preds)\n",
        "mse = mean_squared_error(all_labels, all_preds)\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "\n",
        "to_pil = ToPILImage()\n",
        "\n",
        "# Трансформації для зображень тестового набору\n",
        "test_transform = Compose([\n",
        "    Resize(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_results = []\n",
        "\n",
        "# Пройдемося по всіх файлах у папці\n",
        "for img_path in Path(test_dir).iterdir():\n",
        "    if img_path.is_file() and img_path.suffix in [\".jpg\", \".png\", \".jpeg\"]:  # Фільтруємо лише зображення\n",
        "        # Завантажуємо зображення\n",
        "        img = read_image(str(img_path))\n",
        "        img = test_transform(to_pil(img)).unsqueeze(0).to(device)\n",
        "\n",
        "        # Виконуємо передбачення\n",
        "        with torch.no_grad():\n",
        "            output = base_model(img)\n",
        "            predicted_class = \"Dog\" if output.item() > 0.5 else \"Cat\"\n",
        "\n",
        "        # Додаємо результат\n",
        "        test_results.append({\"FileName\": img_path.name, \"PredictedClass\": predicted_class})\n",
        "\n",
        "# Створюємо DataFrame для результатів\n",
        "test_results_df = pd.DataFrame(test_results)\n",
        "\n",
        "# Виводимо результати в консоль\n",
        "print(test_results_df)\n"
      ]
    }
  ]
}