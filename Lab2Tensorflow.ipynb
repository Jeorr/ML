{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeorr/ML/blob/main/Lab2Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VYEPUEZI2G3",
        "outputId": "576226cb-a9ae-44c4-ce65-cfb6617a0fc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файли успішно розархівовано в /content/Lab2\n",
            "Found 2000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3s/step - accuracy: 0.8474 - loss: 0.3120 - val_accuracy: 0.9750 - val_loss: 0.1026\n",
            "Epoch 2/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 2s/step - accuracy: 0.9731 - loss: 0.0722 - val_accuracy: 0.9680 - val_loss: 0.1067\n",
            "Epoch 3/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 3s/step - accuracy: 0.9744 - loss: 0.0652 - val_accuracy: 0.9700 - val_loss: 0.1186\n",
            "Epoch 4/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 2s/step - accuracy: 0.9884 - loss: 0.0306 - val_accuracy: 0.9700 - val_loss: 0.1248\n",
            "Epoch 5/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 3s/step - accuracy: 0.9948 - loss: 0.0210 - val_accuracy: 0.9700 - val_loss: 0.1212\n",
            "Epoch 6/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 3s/step - accuracy: 0.9912 - loss: 0.0330 - val_accuracy: 0.8880 - val_loss: 0.6020\n",
            "Epoch 7/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 3s/step - accuracy: 0.9829 - loss: 0.0615 - val_accuracy: 0.9530 - val_loss: 0.1965\n",
            "Epoch 8/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 3s/step - accuracy: 0.9776 - loss: 0.0702 - val_accuracy: 0.9600 - val_loss: 0.1332\n",
            "Epoch 9/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3s/step - accuracy: 0.9924 - loss: 0.0214 - val_accuracy: 0.9610 - val_loss: 0.1667\n",
            "Epoch 10/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3s/step - accuracy: 0.9937 - loss: 0.0210 - val_accuracy: 0.9450 - val_loss: 0.2217\n",
            "Epoch 11/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 3s/step - accuracy: 0.9878 - loss: 0.0321 - val_accuracy: 0.9520 - val_loss: 0.1210\n",
            "Epoch 12/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3s/step - accuracy: 0.9984 - loss: 0.0085 - val_accuracy: 0.9590 - val_loss: 0.1613\n",
            "Epoch 13/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 3s/step - accuracy: 0.9967 - loss: 0.0101 - val_accuracy: 0.9610 - val_loss: 0.1963\n",
            "Epoch 14/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 2s/step - accuracy: 0.9950 - loss: 0.0124 - val_accuracy: 0.9690 - val_loss: 0.1244\n",
            "Epoch 15/15\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 3s/step - accuracy: 0.9966 - loss: 0.0117 - val_accuracy: 0.9550 - val_loss: 0.1854\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step\n",
            "Mean Absolute Error (MAE): 0.491\n",
            "Mean Squared Error (MSE): 0.491\n",
            "Found 50 files.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "                                   FileName PredictedClass\n",
            "0    /content/Lab2/cats_and_dogs/test/1.jpg            Dog\n",
            "1   /content/Lab2/cats_and_dogs/test/10.jpg            Cat\n",
            "2   /content/Lab2/cats_and_dogs/test/11.jpg            Cat\n",
            "3   /content/Lab2/cats_and_dogs/test/12.jpg            Dog\n",
            "4   /content/Lab2/cats_and_dogs/test/13.jpg            Cat\n",
            "5   /content/Lab2/cats_and_dogs/test/14.jpg            Cat\n",
            "6   /content/Lab2/cats_and_dogs/test/15.jpg            Cat\n",
            "7   /content/Lab2/cats_and_dogs/test/16.jpg            Cat\n",
            "8   /content/Lab2/cats_and_dogs/test/17.jpg            Dog\n",
            "9   /content/Lab2/cats_and_dogs/test/18.jpg            Dog\n",
            "10  /content/Lab2/cats_and_dogs/test/19.jpg            Cat\n",
            "11   /content/Lab2/cats_and_dogs/test/2.jpg            Dog\n",
            "12  /content/Lab2/cats_and_dogs/test/20.jpg            Cat\n",
            "13  /content/Lab2/cats_and_dogs/test/21.jpg            Dog\n",
            "14  /content/Lab2/cats_and_dogs/test/22.jpg            Cat\n",
            "15  /content/Lab2/cats_and_dogs/test/23.jpg            Dog\n",
            "16  /content/Lab2/cats_and_dogs/test/24.jpg            Dog\n",
            "17  /content/Lab2/cats_and_dogs/test/25.jpg            Cat\n",
            "18  /content/Lab2/cats_and_dogs/test/26.jpg            Dog\n",
            "19  /content/Lab2/cats_and_dogs/test/27.jpg            Dog\n",
            "20  /content/Lab2/cats_and_dogs/test/28.jpg            Cat\n",
            "21  /content/Lab2/cats_and_dogs/test/29.jpg            Cat\n",
            "22   /content/Lab2/cats_and_dogs/test/3.jpg            Dog\n",
            "23  /content/Lab2/cats_and_dogs/test/30.jpg            Dog\n",
            "24  /content/Lab2/cats_and_dogs/test/31.jpg            Dog\n",
            "25  /content/Lab2/cats_and_dogs/test/32.jpg            Cat\n",
            "26  /content/Lab2/cats_and_dogs/test/33.jpg            Dog\n",
            "27  /content/Lab2/cats_and_dogs/test/34.jpg            Cat\n",
            "28  /content/Lab2/cats_and_dogs/test/35.jpg            Cat\n",
            "29  /content/Lab2/cats_and_dogs/test/36.jpg            Cat\n",
            "30  /content/Lab2/cats_and_dogs/test/37.jpg            Cat\n",
            "31  /content/Lab2/cats_and_dogs/test/38.jpg            Cat\n",
            "32  /content/Lab2/cats_and_dogs/test/39.jpg            Dog\n",
            "33   /content/Lab2/cats_and_dogs/test/4.jpg            Dog\n",
            "34  /content/Lab2/cats_and_dogs/test/40.jpg            Cat\n",
            "35  /content/Lab2/cats_and_dogs/test/41.jpg            Dog\n",
            "36  /content/Lab2/cats_and_dogs/test/42.jpg            Dog\n",
            "37  /content/Lab2/cats_and_dogs/test/43.jpg            Dog\n",
            "38  /content/Lab2/cats_and_dogs/test/44.jpg            Dog\n",
            "39  /content/Lab2/cats_and_dogs/test/45.jpg            Cat\n",
            "40  /content/Lab2/cats_and_dogs/test/46.jpg            Dog\n",
            "41  /content/Lab2/cats_and_dogs/test/47.jpg            Cat\n",
            "42  /content/Lab2/cats_and_dogs/test/48.jpg            Dog\n",
            "43  /content/Lab2/cats_and_dogs/test/49.jpg            Dog\n",
            "44   /content/Lab2/cats_and_dogs/test/5.jpg            Cat\n",
            "45  /content/Lab2/cats_and_dogs/test/50.jpg            Cat\n",
            "46   /content/Lab2/cats_and_dogs/test/6.jpg            Cat\n",
            "47   /content/Lab2/cats_and_dogs/test/7.jpg            Cat\n",
            "48   /content/Lab2/cats_and_dogs/test/8.jpg            Cat\n",
            "49   /content/Lab2/cats_and_dogs/test/9.jpg            Cat\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "from tensorflow.keras import layers, models, utils\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Розархівовуємо zip файл, якщо він існує\n",
        "zip_path = '/content/drive/MyDrive/ML/cats_and_dogs.zip'\n",
        "extract_to_path = '/content/Lab2'\n",
        "if os.path.exists(zip_path):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to_path)\n",
        "    print(f\"Файли успішно розархівовано в {extract_to_path}\")\n",
        "else:\n",
        "    print(f\"Файл {zip_path} не знайдено.\")\n",
        "\n",
        "# Підготовка шляхів до наборів даних\n",
        "train_dir = '/content/Lab2/cats_and_dogs/train'\n",
        "validation_dir = '/content/Lab2/cats_and_dogs/validation'\n",
        "test_dir = '/content/Lab2/cats_and_dogs/test'\n",
        "\n",
        "# Генератор для тренувальних даних\n",
        "train_generator = utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=(150, 150),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False,\n",
        "    pad_to_aspect_ratio=False,\n",
        "    data_format=None,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Генератор для валідаційних даних\n",
        "validation_generator = utils.image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=(150, 150),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False,\n",
        "    pad_to_aspect_ratio=False,\n",
        "    data_format=None,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# спроба збудувати модель з нуля провалилася, після багатьох спроб вона так і не змогла демонструвати\n",
        "# хороші результати. Спробуємо попередньо навчену модель як базову для нашої\n",
        "base_model = tf.keras.applications.EfficientNetB0(\n",
        "    input_shape=(150, 150, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "base_model.trainable = True  # Розморозити всі шари\n",
        "\n",
        "# Заморозити лише верхні шари для збереження попереднього навчання\n",
        "for layer in base_model.layers[:100]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Компіляція з меншою швидкістю навчання\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Навчання моделі\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=15,\n",
        "    validation_data=validation_generator,\n",
        ")\n",
        "\n",
        "# Передбачення\n",
        "prediction_based_on_validation_data = model.predict(validation_generator)\n",
        "# Округлення та перетворення на цілі числа (0 або 1)\n",
        "prediction_based_on_validation_data = np.round(prediction_based_on_validation_data).flatten()\n",
        "\n",
        "# Справжні мітки\n",
        "real_data = np.concatenate([y for x, y in validation_generator], axis=0)\n",
        "\n",
        "# Обчислення MAE та MSE\n",
        "mae = mean_absolute_error(real_data, prediction_based_on_validation_data)\n",
        "mse = mean_squared_error(real_data, prediction_based_on_validation_data)\n",
        "\n",
        "# Виведення результатів\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "\n",
        "# оскільки тестови картинки в нас не розбиті по категоріям, перевірити відповідність\n",
        "# тестовим даним нам доведеться робити вручну\n",
        "# для генератора тестових даних відключаємо мітки, відключаємо перемішування\n",
        "test_generator = utils.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    labels=None,\n",
        "    label_mode=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=64,\n",
        "    image_size=(150, 150),\n",
        "    shuffle=False,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Передбачення на тестових даних\n",
        "prediction_based_on_test_data = model.predict(test_generator)\n",
        "\n",
        "# Інтерпретація результатів\n",
        "predicted_classes = np.round(prediction_based_on_test_data).flatten()\n",
        "\n",
        "# Отримання назв файлів\n",
        "file_names = test_generator.file_paths\n",
        "\n",
        "# Створюємо DataFrame для результатів\n",
        "results = pd.DataFrame({\n",
        "    \"FileName\": file_names,\n",
        "    \"PredictedClass\": [\"Dog\" if cls == 1 else \"Cat\" for cls in predicted_classes.flatten()]\n",
        "})\n",
        "\n",
        "# Виводимо результати в консоль\n",
        "print(results)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1VEi99ST-gm8Dpe9evTvT7caPxFLcpyLa",
      "authorship_tag": "ABX9TyPPba4LesUw1vvJgGhFORxx",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}